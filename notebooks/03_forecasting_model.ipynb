{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c513e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0f7f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>time_bucket</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>net_flow_lag_1</th>\n",
       "      <th>net_flow_lag_2</th>\n",
       "      <th>net_flow_lag_3</th>\n",
       "      <th>net_flow_lag_6</th>\n",
       "      <th>roll_mean_3</th>\n",
       "      <th>roll_std_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000959</td>\n",
       "      <td>2022-09-12 11:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000959</td>\n",
       "      <td>2022-09-12 11:30:00</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000959</td>\n",
       "      <td>2022-09-12 12:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000959</td>\n",
       "      <td>2022-09-12 12:30:00</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000959</td>\n",
       "      <td>2022-09-12 13:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.081666</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_id         time_bucket  hour  dow  net_flow_lag_1  net_flow_lag_2  \\\n",
       "0     000959 2022-09-12 11:00:00    11    0            -1.0            -1.0   \n",
       "1     000959 2022-09-12 11:30:00    11    0             1.0            -1.0   \n",
       "2     000959 2022-09-12 12:00:00    12    0             1.0             1.0   \n",
       "3     000959 2022-09-12 12:30:00    12    0            -2.0             1.0   \n",
       "4     000959 2022-09-12 13:00:00    13    0             2.0            -2.0   \n",
       "\n",
       "   net_flow_lag_3  net_flow_lag_6  roll_mean_3  roll_std_3    target  \n",
       "0             1.0             0.0    -0.333333    1.154701  balanced  \n",
       "1            -1.0             5.0    -0.333333    1.154701  balanced  \n",
       "2            -1.0            -1.0     0.333333    1.154701  balanced  \n",
       "3             1.0             1.0     0.000000    1.732051  balanced  \n",
       "4             1.0            -1.0     0.333333    2.081666  balanced  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('processed_data/net_flow_model_table.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51b96bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "balanced    17126824\n",
       "surplus       321574\n",
       "shortage      296246\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb21074",
   "metadata": {},
   "source": [
    "- Can't use train_test_split from sklearn on this data since it's time series data therefore opted for TimeSeriesSplit from sklearn. \n",
    "- Make sure to sort data by TIME. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a609362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training & testing set\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "\n",
    "df = df.sort_values('time_bucket').reset_index(drop = True) \n",
    "\n",
    "X = df.drop(columns = ['station_id', 'time_bucket', 'target'])\n",
    "y = df['target']\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 3) #3 splits only because 5 seems to crash computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167bed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    balanced      0.981     0.505     0.667   4281437\n",
      "    shortage      0.035     0.537     0.065     74334\n",
      "     surplus      0.043     0.575     0.080     80390\n",
      "\n",
      "    accuracy                          0.507   4436161\n",
      "   macro avg      0.353     0.539     0.270   4436161\n",
      "weighted avg      0.948     0.507     0.646   4436161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    balanced      0.979     0.504     0.665   4271529\n",
      "    shortage      0.035     0.522     0.066     79511\n",
      "     surplus      0.045     0.567     0.084     85121\n",
      "\n",
      "    accuracy                          0.505   4436161\n",
      "   macro avg      0.353     0.531     0.272   4436161\n",
      "weighted avg      0.945     0.505     0.644   4436161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    balanced      0.982     0.523     0.683   4281449\n",
      "    shortage      0.036     0.543     0.068     74193\n",
      "     surplus      0.047     0.611     0.088     80519\n",
      "\n",
      "    accuracy                          0.525   4436161\n",
      "   macro avg      0.355     0.559     0.279   4436161\n",
      "weighted avg      0.949     0.525     0.662   4436161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def build_model():\n",
    "    return LogisticRegression(\n",
    "        multi_class = 'multinomial',\n",
    "        max_iter = 500,\n",
    "        class_weight = 'balanced', \n",
    "        n_jobs = -1,\n",
    "        solver = 'lbfgs'\n",
    "    )\n",
    "\n",
    "reports = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X), start=1):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    model = build_model()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f'{fold}')\n",
    "    print(classification_report(y_test, y_pred, digits = 3))\n",
    "\n",
    "    reports.append(\n",
    "        classification_report(\n",
    "            y_test, y_pred, output_dict = True\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3afb0ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fold  shortage_recall  surplus_recall  macro_f1\n",
      "0     1         0.536753        0.575146  0.270455\n",
      "1     2         0.521777        0.567475  0.271858\n",
      "2     3         0.543232        0.611346  0.279407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fold               2.000000\n",
       "shortage_recall    0.533921\n",
       "surplus_recall     0.584656\n",
       "macro_f1           0.273906\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggregate cross-val performance\n",
    "cv_summary = (\n",
    "    pd.DataFrame([\n",
    "        {\n",
    "            \"fold\": i + 1,\n",
    "            \"shortage_recall\": r[\"shortage\"][\"recall\"],\n",
    "            \"surplus_recall\":  r[\"surplus\"][\"recall\"],\n",
    "            \"macro_f1\":        r[\"macro avg\"][\"f1-score\"],\n",
    "        }\n",
    "        for i, r in enumerate(reports)\n",
    "    ])\n",
    ")\n",
    "\n",
    "print(cv_summary)\n",
    "cv_summary.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f62627",
   "metadata": {},
   "source": [
    "- model correctly identifies over half of all real shortages and surpluses 30 min in advance, using only real net flow history and time features.\n",
    "- macro f1 relatively low but that's ok because it averages performance across three classes: shortage (rare), surplus (rare) and balanced (dominant). 96.5% of cases are balanced while minority classes are ~1-2% so macro f1 is going be low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ad0e76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    balanced      0.985     0.684     0.807   4281437\n",
      "    shortage      0.049     0.577     0.090     74334\n",
      "     surplus      0.074     0.541     0.131     80390\n",
      "\n",
      "    accuracy                          0.679   4436161\n",
      "   macro avg      0.369     0.601     0.343   4436161\n",
      "weighted avg      0.953     0.679     0.783   4436161\n",
      "\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    balanced      0.983     0.680     0.804   4271529\n",
      "    shortage      0.050     0.558     0.092     79511\n",
      "     surplus      0.076     0.533     0.133     85121\n",
      "\n",
      "    accuracy                          0.675   4436161\n",
      "   macro avg      0.370     0.591     0.343   4436161\n",
      "weighted avg      0.949     0.675     0.779   4436161\n",
      "\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    balanced      0.986     0.691     0.813   4281449\n",
      "    shortage      0.052     0.595     0.095     74193\n",
      "     surplus      0.080     0.582     0.141     80519\n",
      "\n",
      "    accuracy                          0.688   4436161\n",
      "   macro avg      0.373     0.623     0.350   4436161\n",
      "weighted avg      0.954     0.688     0.788   4436161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_reports = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X), start=1):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=80,\n",
    "        max_depth=8,\n",
    "        min_samples_leaf=100,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    print(f'{fold}')\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    rf_reports.append(\n",
    "        classification_report(y_test, y_pred, output_dict=True)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6050768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fold  shortage_recall  surplus_recall  macro_f1\n",
      "0     1         0.576667        0.541398  0.342579\n",
      "1     2         0.558111        0.533405  0.343245\n",
      "2     3         0.594760        0.581776  0.349674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fold               2.000000\n",
       "shortage_recall    0.576513\n",
       "surplus_recall     0.552193\n",
       "macro_f1           0.345166\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_summary = pd.DataFrame([\n",
    "    {\n",
    "        \"fold\": i + 1,\n",
    "        \"shortage_recall\": r[\"shortage\"][\"recall\"],\n",
    "        \"surplus_recall\":  r[\"surplus\"][\"recall\"],\n",
    "        \"macro_f1\":        r[\"macro avg\"][\"f1-score\"],\n",
    "    }\n",
    "    for i, r in enumerate(rf_reports)\n",
    "])\n",
    "\n",
    "print(rf_summary)\n",
    "rf_summary.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2644fb7",
   "metadata": {},
   "source": [
    "Compared to Logisitic Regression, the Random Forest saw:\n",
    "- 4-5pp improvement in shortage recall \n",
    "- Macro F1 up by approx 0.07 (relatively big jump in an imbalanced 3 class problem)\n",
    "- Shortage recall is most important metric because shortages are more operationally costly so the improved shortage recall (53% to 57%) is meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c66f6662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    17126824\n",
       "2      321574\n",
       "0      296246\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {\n",
    "    \"shortage\": 0,\n",
    "    \"balanced\": 1,\n",
    "    \"surplus\":  2\n",
    "}\n",
    "\n",
    "y_enc = df[\"target\"].map(label_map)\n",
    "y_enc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d428a82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    shortage      0.781     0.016     0.032     74334\n",
      "    balanced      0.966     1.000     0.983   4281437\n",
      "     surplus      0.691     0.038     0.072     80390\n",
      "\n",
      "    accuracy                          0.966   4436161\n",
      "   macro avg      0.813     0.351     0.362   4436161\n",
      "weighted avg      0.958     0.966     0.950   4436161\n",
      "\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    shortage      0.737     0.016     0.032     79511\n",
      "    balanced      0.964     1.000     0.981   4271529\n",
      "     surplus      0.709     0.046     0.087     85121\n",
      "\n",
      "    accuracy                          0.964   4436161\n",
      "   macro avg      0.803     0.354     0.367   4436161\n",
      "weighted avg      0.955     0.964     0.947   4436161\n",
      "\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    shortage      0.718     0.019     0.036     74193\n",
      "    balanced      0.966     0.999     0.983   4281449\n",
      "     surplus      0.684     0.053     0.098     80519\n",
      "\n",
      "    accuracy                          0.966   4436161\n",
      "   macro avg      0.790     0.357     0.372   4436161\n",
      "weighted avg      0.957     0.966     0.951   4436161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb \n",
    "\n",
    "xgb_reports = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X), start=1):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y_enc.iloc[train_idx], y_enc.iloc[test_idx]\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=3,\n",
    "        n_estimators=150,        \n",
    "        max_depth=5,             # shallow trees\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        tree_method=\"hist\",      # memory-efficient\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_jobs=2,                # NOT all cores\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f'{fold}')\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_test,\n",
    "            y_pred,\n",
    "            target_names=[\"shortage\", \"balanced\", \"surplus\"],\n",
    "            digits=3\n",
    "        )\n",
    "    )\n",
    "\n",
    "    xgb_reports.append(\n",
    "        classification_report(\n",
    "            y_test,\n",
    "            y_pred,\n",
    "            output_dict=True\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79965411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fold  shortage_recall  surplus_recall  macro_f1\n",
      "0     1         0.016372        0.037990  0.362210\n",
      "1     2         0.016463        0.046087  0.366733\n",
      "2     3         0.018600        0.052832  0.372316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fold               2.000000\n",
       "shortage_recall    0.017145\n",
       "surplus_recall     0.045636\n",
       "macro_f1           0.367086\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_summary = pd.DataFrame([\n",
    "    {\n",
    "        \"fold\": i + 1,\n",
    "        \"shortage_recall\": r[\"0\"][\"recall\"],   # 0 -> shortage\n",
    "        \"surplus_recall\":  r[\"2\"][\"recall\"],   # 2 -> surplus\n",
    "        \"macro_f1\":        r[\"macro avg\"][\"f1-score\"],\n",
    "    }\n",
    "    for i, r in enumerate(xgb_reports)\n",
    "])\n",
    "\n",
    "print(xgb_summary)\n",
    "xgb_summary.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e353f77e",
   "metadata": {},
   "source": [
    "- XGBoost Model failed as it fails to predict shortages or surpluses. Instead it overwhelmingly predicts the balanced class.  \n",
    "- Reject this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33ac50c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_status\n",
       "balanced    0.674875\n",
       "shortage    0.197840\n",
       "surplus     0.127285\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = RandomForestClassifier(\n",
    "    n_estimators=120, #slightly increase n_estimators (from 80)\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=100,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_model.fit(X, y)\n",
    "\n",
    "#make predictions\n",
    "rf_preds = df[[\"station_id\", \"time_bucket\"]].copy()\n",
    "rf_preds[\"predicted_status\"] = best_model.predict(X)\n",
    "\n",
    "rf_preds.head()\n",
    "rf_preds[\"predicted_status\"].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c18f3519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_status\n",
       "balanced    0.674875\n",
       "shortage    0.197840\n",
       "surplus     0.127285\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "#save predictions\n",
    "out_dir = Path('processed_data')\n",
    "out_dir.mkdir(exist_ok = True)\n",
    "\n",
    "rf_preds.to_parquet(\n",
    "    out_dir / 'rf_predictions.parquet',\n",
    "    index = False\n",
    ")\n",
    "\n",
    "test = pd.read_parquet(\"processed_data/rf_predictions.parquet\")\n",
    "test.shape\n",
    "test[\"station_id\"].nunique()\n",
    "test[\"predicted_status\"].value_counts(normalize = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "your_env_name",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
